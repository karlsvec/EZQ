# How to use this config file, in 3 easy steps:
# 1. To add a new launch TYPE, add an entry with a new name under the ami_map
#    section. Reference the appropriate AMI. The TYPE is really just a label
#    for associating a group of settings. You can have two TYPEs that are
#    exactly the same except for one minor detail in the userdata (for example).
# 2. Fill out any required overrides for a launch type in the security,
#    launch_settings, and userdata sections. Use the same type name as in step
#    one if you're setting up a new type.
# 3. There are really only two steps.

# Map type labels to specific AMIs. New types can be added by adding a
# new label and AMI in this section

# 'ami-3862ff50' is 30gb windows base

ami_map:
  # Windows
  worker_ISA:         'ami-2a354042'
  worker_r2_ISA:      'ami-2a354042'
  server_worker_ISU:  'ami-2a354042'
  server_worker_IN:   'ami-2a354042'
  worker_mmp_dev:     'ami-2a354042'
  worker_mmp_staging: 'ami-2a354042'
  worker_mmp_prod:    'ami-2a354042'
  worker_pzm_md_dev:  'ami-2a354042'
  worker_pzm_md_dev_long:  'ami-2a354042'
  worker_pzm_md_prod: 'ami-2a354042'
  worker_pzm_md_prod_long: 'ami-2a354042'
  pregrid:            'ami-2a354042'
  pregrid_ISA:        'ami-2a354042'
  pregrid_ISU:        'ami-2a354042'
  pregrid_IN:         'ami-2a354042'
  # Linux
  reporthandler:  'ami-8eacd1e6'
  aggregator:     'ami-8eacd1e6'
  aggregator_r2:  'ami-2e44c546' #'ami-f4419c9c'
  errorhandler:   'ami-8eacd1e6'
  builder:        'ami-8eacd1e6'
  pzm_report_dev: 'ami-b06519d8' # Paravirtual image
  landsat:        'ami-b06519d8'
  linux_base:     'ami-8eacd1e6' # HVM image

spot_subnets:
  - subnet-b2f1ff9a # spot-1
  - subnet-83f1ffab # spot-2
  - subnet-9bf1ffb3 # spot-3
  - subnet-92f1ffba # spot-4
  - subnet-f1d7dfd9 # spot-5
  - subnet-c7d7dfef # spot-6
  - subnet-d6d7dffe # spot-7
  - subnet-3be8e013 # spot-8
  - subnet-1ee8e036 # spot-9
  - subnet-6be8e043 # spot-10
  - subnet-63e8e04b # spot-11
  - subnet-72e8e05a # spot-12
  - subnet-54e8e07c # spot-13
  - subnet-a1e8e089 # spot-14
  - subnet-b7e8e09f # spot-15
  - subnet-81e8e0a9 # spot-16
  - subnet-ece8e0c4 # spot-17
  - subnet-fae8e0d2 # spot-18
  - subnet-f2e8e0da # spot-19
  - subnet-dce8e0f4 # spot-20


# Security-related settings for instances. The settings in 'base' will be merged
# with any settings specified on a per-type basis, with the per-type settings
# taking precedence. All available options appear in the base section.
security:
  base:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-fc94b793' # development-private

    # If you override this on a per-type basis, be aware that the *values* in
    # the array will not be merged. You must override the entire array.
    security_groups: ['dev-base','dev-kibitz-worker']

  errorhandler:
    security_groups: ['dev-base','dev-kibitz-worker','dev-dashboard']

  worker_mmp_dev:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-fc94b793'
    security_groups: ['dev-base','dev-kibitz-worker']

  worker_mmp_staging:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-fc94b793'
    security_groups: ['dev-base','dev-kibitz-worker']

  worker_mmp_prod:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-cb9ebda4'
    security_groups: ['production-worker']

  worker_pzm_md_dev:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-fc94b793'
    security_groups: ['dev-base','dev-kibitz-worker']

  worker_pzm_md_dev_long:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-fc94b793'
    security_groups: ['dev-base','dev-kibitz-worker']

  pzm_report_dev:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-fc94b793'
    security_groups: ['dev-base','dev-kibitz-worker']

  worker_pzm_md_prod:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-cb9ebda4'
    # If you override this on a per-type basis, be aware that the *values* in
    # the array will not be merged. You must override the entire array.
    security_groups: ['production-worker']

  worker_pzm_md_prod_long:
    vpc_id: 'vpc-e894b787'
    vpc_subnet: 'subnet-cb9ebda4'
    # If you override this on a per-type basis, be aware that the *values* in
    # the array will not be merged. You must override the entire array.
    security_groups: ['production-worker']

# The base settings get merged with any per-type settings. All available options
# appear in the base section.
launch_settings:
  base:
    size: 't2.micro'
    count: 1

  pregrid:
    size: 't2.medium'

  pregrid_ISA:
    size: 't2.medium'

  pregrid_ISU:
    size: 't2.medium'

  pregrid_IN:
    size: 't2.medium'

  worker_ISA:
    size: 'm1.medium'

  worker_r2_ISA:
    size: 'r3.xlarge'
    #size: 'r3.4xlarge'

  server_worker_ISU:
    size: 'm1.xlarge'

  server_worker_IN:
    size: 'm1.medium'

  worker_mmp_dev:
    size: 't2.medium'
    bill_to: 'MMP360'

  worker_mmp_staging:
    size: 't2.medium'
    bill_to: 'MMP360'

  worker_mmp_prod:
    size: 't2.medium'
    bill_to: 'MMP360'

  worker_pzm_md_dev:
    size: 't2.medium'
    bill_to: 'PZM'

  worker_pzm_md_dev_long:
    size: 't2.medium'
    bill_to: 'PZM'

  pzm_report_dev:
    size: 't1.micro'
    bill_to: 'PZM'

  worker_pzm_md_prod:
    size: 't2.medium'
    bill_to: 'PZM'
    count: 1

  worker_pzm_md_prod_long:
    size: 't2.medium'
    bill_to: 'PZM'
    count: 1

  aggregator_r2:
    size: 'm3.2xlarge'

  aggregator:
    size: 'm3.medium'

  reporthandler:
    size: 'm3.medium'

  errorhandler:
    size: 't1.micro'
    bill_to: 'EZQ-6k_dev'
    
  landsat:
    size: 'm1.small'
    bill_to: 'EZQ-6k_dev'

  linux_base:
    size: 't2.micro'
    bill_to: 'EZQ-6k_dev'

# The information in this section is used to populate the userdata on
# an instance prior to launch. The base section is merged with all launch types.
# Since the userdata is very flexible, NOT ALL POSSIBLE SETTINGS APPEAR IN THE
# BASE SECTION. Any boolean, numeric, or string value can be specified in
# the per-type userdata sections.
userdata:
  base:
    deploy_bucket: 6k_test.praxik
    # The gdb file to use
    gdb_bucket: 6k_test.praxik
    man_bucket: 6k_test.praxik
    r2_man_bucket: 6k_test.praxik
    # Turn on Loggly logging. To turn this off for a specific profile, set the
    # value of this pair to '' in the override section for that profile.
    loggly_token: 44cf8878-ce2a-44af-8a41-e6f529de35fc
    # Log severity threshold for sending mesage to Loggly. You can override this
    # in individual profiles. Valid values are unknown, fatal, error, warn,
    # info, and debug
    loggly_level: error
    # App name used when sending messages to Loggly. You should override this
    # in each and every profile.
    app_name: "nimbus_base.processor"

  worker_ISA:
    deploy_key: arks/default/server_worker_x64.zip
    number_of_processes: auto
    gdb_key: iowammp.gdb.zip
    gdb_install_name: iowammp.gdb
    man_key: MON_COB_weps.zip
    r2_man_key: MON_COB_skels.zip
    receive_queue_name: 6k_task
    keep_alive_check_interval: 30
    server_worker_command: "6k_server_worker.exe --gdbname iowammp.gdb --workerid $pid"
    app_name: "worker_ISA.processor"
    error_queue_name: 6k_error

  worker_r2_ISA:
    deploy_key: arks/default/worker_r2p2d_x64.zip
    number_of_processes: auto
    gdb_key: iowammp.gdb.zip
    gdb_install_name: iowammp.gdb
    man_key: ISA_weps.zip
    r2_man_key: ISA_skels.zip
    receive_queue_name: 6k_task_r2
    app_name: "worker_r2_ISA.processor"
    error_queue_name: 6k_error

  server_worker_ISU:
    deploy_key: arks/default/server_worker_x64.zip
    number_of_processes: auto
    gdb_key: iowammp.gdb.zip
    gdb_install_name: iowammp.gdb
    man_key: ISU_heaton_weps.zip
    r2_man_key: ISU_heaton_skels.zip
    receive_queue_name: purdue_task
    keep_alive_check_interval: 30
    server_worker_command: "6k_server_worker.exe --gdbname iowammp.gdb --workerid $pid"
    app_name: "server_worker_ISU.processor"
    error_queue_name: purdue_error
    use_instance_store: false

  server_worker_IN:
    deploy_key: arks/default/server_worker_x64.zip
    number_of_processes: auto
    gdb_key: iowammp.gdb.zip
    gdb_install_name: iowammp.gdb
    man_key: MON_COB_weps.zip
    r2_man_key: MON_COB_skels.zip
    receive_queue_name: IN_task
    keep_alive_check_interval: 30
    server_worker_command: "6k_server_worker.exe --gdbname iowammp.gdb --workerid $pid"
    app_name: "server_worker_IN.processor"
    error_queue_name: IN_error

  worker_mmp_dev:
    deploy_key: arks/default/iowammp.zip
    number_of_processes: 2
    db_ip: persistence.development.internal.mmp360.com
    db_port: 5432
    db_user_name: iowammp
    db_password: 1234
    db_name: iowammp_web_development_reports
    geoserver_ip: persistence.gis.readonly.internal.agsolver.com
    geoserver_port: 5432
    gs_db_username: postgres
    gs_db_password: agsolver_postgres
    s3_bucket: web_development
    app_name: "worker_mmp_dev.processor"
    use_instance_store: false
    receive_queue_name: "mmp360_job_web_development"
    error_queue_name: "mmp360_error_web_development"
    result_queue_name: "mmp360_result_web_development"

  worker_mmp_staging:
    deploy_key: arks/default/iowammp.zip
    number_of_processes: 2
    db_ip: persistence.staging.mmp360.com
    db_port: 5432
    db_user_name: iowammp
    db_password: 1234
    db_name: iowammp_web_development_reports
    geoserver_ip: persistence.gis.readonly.internal.agsolver.com
    geoserver_port: 5432
    gs_db_username: postgres
    gs_db_password: agsolver_postgres
    s3_bucket: staging
    app_name: "worker_mmp_staging.processor"
    use_instance_store: false
    receive_queue_name: "mmp360_job_staging"
    error_queue_name: "mmp360_error_staging"
    result_queue_name: "mmp360_result_staging"

  worker_mmp_prod:
    deploy_key: arks/default/iowammp_prod.zip
    number_of_processes: 2
    db_ip: persistence.production.internal.mmp360.com
    db_port: 5432
    db_user_name: iowammp
    db_password: dan4yees7d
    db_name: iowammp_production_reports
    geoserver_ip: persistence.gis.readonly.internal.agsolver.com
    geoserver_port: 5432
    gs_db_username: postgres
    gs_db_password: agsolver_postgres
    s3_bucket: production
    app_name: "worker_mmp_prod.processor"
    use_instance_store: false
    receive_queue_name: "mmp360_job_production"
    error_queue_name: "mmp360_error_production"
    result_queue_name: "mmp360_result_production"

  worker_pzm_md_dev:
    deploy_key: arks/default/md_worker.zip
    number_of_processes: 1
    s3_bucket: web_development
    app_name: "worker_pzm_md_dev.processor"
    use_instance_store: false
    receive_queue_name: "roi_job_web_development"
    error_queue_name: "roi_error_web_development"
    result_queue_name: "roi_results_web_development"

  worker_pzm_md_dev_long:
    deploy_key: arks/default/md_worker.zip
    number_of_processes: 1
    s3_bucket: web_development
    app_name: "worker_pzm_md_dev.processor"
    use_instance_store: false
    receive_queue_name: "roi_long_job_web_development"
    error_queue_name: "roi_error_web_development"
    result_queue_name: "roi_results_web_development"

  pzm_report_dev:
    deploy_key: arks/default/pzm_reportmaker.zip
    number_of_processes: 1
    s3_bucket: web_development
    app_name: "pzm_report.processor"
    use_instance_store: false
    report_bucket: "roi.agsolver"
    report_key_base: "web_development/reports"
    receive_queue_name: "roi_report_web_development"
    error_queue_name: "roi_error_web_development"
    result_queue_name: "roi_results_web_development"

  worker_pzm_md_prod:
    deploy_key: arks/default/md_worker_prod.zip
    number_of_processes: 1
    s3_bucket: production
    use_instance_store: false
    receive_queue_name: "roi_job_production"
    error_queue_name: "roi_error_production"
    result_queue_name: "roi_results_production"

  worker_pzm_md_prod_long:
    deploy_key: arks/default/md_worker_prod.zip
    number_of_processes: 1
    s3_bucket: production
    use_instance_store: false
    receive_queue_name: "roi_long_job_production"
    error_queue_name: "roi_error_production"
    result_queue_name: "roi_results_production"

  pregrid:
    deploy_key: arks/default/pregrid_x64.zip

  pregrid_ISA:
    deploy_key: arks/default/pregrid_x64.zip #pregrid_r2d2_x64.zip
    gdb_key: iowammp.gdb.zip
    gdb_install_name: iowammp.gdb
    man_key: MON_COB_weps.zip
    r2_man_key: MON_COB_skels.zip
    receive_queue_name: 6k_job
    app_name: "pregrid_ISA.processor"
    error_queue_name: 6k_error

  pregrid_ISU:
    deploy_key: arks/default/pregrid_x64.zip
    gdb_key: iowammp.gdb.zip
    gdb_install_name: iowammp.gdb
    man_key: ISU_heaton_weps.zip
    r2_man_key: ISU_heaton_skels.zip
    receive_queue_name: purdue_job
    app_name: "pregrid_ISU.processor"
    error_queue_name: purdue_error

  pregrid_IN:
    deploy_key: arks/default/pregrid_x64.zip
    gdb_key: iowammp.gdb.zip
    gdb_install_name: iowammp.gdb
    man_key: MON_COB_weps.zip
    r2_man_key: MON_COB_skels.zip
    receive_queue_name: IN_job
    app_name: "pregrid_IN.processor"
    error_queue_name: IN_error

  reporthandler:
    deploy_key: arks/default/reporthandler.zip
    receive_queue_name: 6k_report_gen
    app_name: "reporthandler.processor"

  aggregator_r2:
    deploy_key: arks/default/aggregator_r2.zip
    receive_queue_name: 6k_aggregator_r2
    app_name: "aggregator_r2.processor"

  aggregator:
    deploy_key: arks/default/aggregator.zip
    receive_queue_name: 6k_aggregator
    app_name: "aggregator.processor"

  errorhandler:
    deploy_key: arks/default/errorhandler.zip
    app_name: "errorhandler.processor"
   
  landsat:
    deploy_key: arks/default/landsat.zip
    app_name: "landsat.processor"
    receive_queue_name: landsat_worker
    error_queue_name: landsat_error
    result_queue_name: landsat_result

